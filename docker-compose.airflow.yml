# Airflow - à lancer avec : docker-compose -f docker-compose.yml -f docker-compose.airflow.yml up -d
# Interface Airflow : http://localhost:8080 (admin / admin par défaut)

version: '3.8'

services:
  airflow-db:
    image: postgres:13-alpine
    container_name: ocr-airflow-db
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      retries: 5
    networks:
      - ocr-network
    restart: unless-stopped

  airflow:
    image: apache/airflow:2.7.3-python3.11
    container_name: ocr-airflow
    depends_on:
      airflow-db:
        condition: service_healthy
      backend:
        condition: service_started
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
      # Sous Windows/WSL : 0 évite les erreurs de permissions sur les volumes
      AIRFLOW_UID: "0"
      # URL de l'API OCR (nom du service backend dans Docker)
      OCR_API_URL: http://backend:8000
      # Inbox = même dossier que les uploads de l'app (dès qu'un fichier est déposé, le sensor le voit)
      OCR_INBOX_PATH: /opt/airflow/inbox
      OCR_USERNAME: aitdjoudi@gmail.com
      OCR_PASSWORD: boussad
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      # Partagé avec le backend : les fichiers uploadés dans l'app sont vus par Airflow
      - ./backend/uploads:/opt/airflow/inbox
      - airflow_logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    command: airflow standalone
    restart: unless-stopped
    networks:
      - ocr-network

volumes:
  airflow_postgres_data:
  airflow_logs:
